{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "from deepcpf1_network import SeqDeepCpf1Net\n",
    "from deepcpf1_network import SequenceDataset\n",
    "from deepcpf1_network import predict\n",
    "from deepcpf1_network import decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing weights for the models\n",
      "50 models are loaded.\n"
     ]
    }
   ],
   "source": [
    "args ={'test' : \"./data/test.csv\",\n",
    "'output' : \"output.csv\",\n",
    "'model_path': \"./weights/\",\n",
    "'seed':1,\n",
    "'sequence_length' : 34,\n",
    "'kernel_size' :  5,\n",
    "'pool_size' :2,\n",
    "'no_cuda' : True,\n",
    "}\n",
    "\n",
    "args = dotdict(args)\n",
    "\n",
    "\n",
    "model_state_paths = []\n",
    "# Loading Model for Inference\n",
    "print(\"Listing weights for the models\")\n",
    "for file in os.listdir(args.model_path):\n",
    "    if file.endswith(\".pt\"):\n",
    "        model_state_paths.append(os.path.join(args.model_path, file))\n",
    "\n",
    "print(f\"{len(model_state_paths)} models are loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing weights for the models\n",
      "50 models are loaded.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "test_kwargs = {'batch_size': 300, 'shuffle': False}\n",
    "\n",
    "model_state_paths = []\n",
    "# Loading Model for Inference\n",
    "print(\"Listing weights for the models\")\n",
    "for file in os.listdir(args.model_path):\n",
    "    if file.endswith(\".pt\"):\n",
    "        model_state_paths.append(os.path.join(args.model_path, file))\n",
    "\n",
    "print(f\"{len(model_state_paths)} models are loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34 bp synthetic target and target context sequence\\n(4 bp + PAM + 23 bp protospacer + 3 bp)  \\\n",
      "0                    TTGCTTTAAAACTCGCAAGGCTTTCTGCTTGACC                                            \n",
      "1                    CAGATTTAAAGACTTTCTGCTGTATTTGAGATGC                                            \n",
      "2                    GTAGTTTAAAGCCTTTTTTATTGTATCTTGTTGC                                            \n",
      "3                    CCCTTTTAAATTCTGTGCAGACCATAGTGCTGCT                                            \n",
      "4                    TTACTTTAACACTCTCAGTTGGCCCATATTCACA                                            \n",
      "...                                                 ...                                            \n",
      "1287                 CACCTTTTTTGATTATGATTACGGTGCTCCCTGT                                            \n",
      "1288                 CAGATTTTTTGCTGTTGGTGAAGGCCCTTGAAGA                                            \n",
      "1289                 TTTCTTTTTTGGCATTGCGGAGCTTATACATTCC                                            \n",
      "1290                 CTGGTTTTTTTGCTCCTTCTCGTTTTTCACAGCA                                            \n",
      "1291                 CTGTTTTTTTTTCTTCTTCCGGAGTTTGCCACTT                                            \n",
      "\n",
      "      Indel freqeuncy\\n(Background substracted, %)  CA  \n",
      "0                                        73.775671 NaN  \n",
      "1                                        68.350168 NaN  \n",
      "2                                        -5.948064 NaN  \n",
      "3                                        73.786402 NaN  \n",
      "4                                        43.073341 NaN  \n",
      "...                                            ...  ..  \n",
      "1287                                      0.117944 NaN  \n",
      "1288                                      0.120192 NaN  \n",
      "1289                                      0.330033 NaN  \n",
      "1290                                     -6.444774 NaN  \n",
      "1291                                      0.194363 NaN  \n",
      "\n",
      "[1292 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juyoungshin/Documents/code_repo/DeepCpf1_torch_public/deepcpf1_network.py:147: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.Seq_deepCpf1_C1.weight)\n"
     ]
    }
   ],
   "source": [
    "seq_deep_cpf1 = SeqDeepCpf1Net(args).to(device)\n",
    "\n",
    "# Load test data\n",
    "testing_data = SequenceDataset(csv_file=args.test, args=args)\n",
    "test_dataloader = DataLoader(testing_data, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_models = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions_by_models = {model_no : (sequence_vector, y_true, y_pred)}\n",
    "\n",
    "The tuple is composed of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data: 0/50-th model tested\n",
      "Predicting on test data: 1/50-th model tested\n",
      "Predicting on test data: 2/50-th model tested\n",
      "Predicting on test data: 3/50-th model tested\n",
      "Predicting on test data: 4/50-th model tested\n",
      "Predicting on test data: 5/50-th model tested\n",
      "Predicting on test data: 6/50-th model tested\n",
      "Predicting on test data: 7/50-th model tested\n",
      "Predicting on test data: 8/50-th model tested\n",
      "Predicting on test data: 9/50-th model tested\n",
      "Predicting on test data: 10/50-th model tested\n",
      "Predicting on test data: 11/50-th model tested\n",
      "Predicting on test data: 12/50-th model tested\n",
      "Predicting on test data: 13/50-th model tested\n",
      "Predicting on test data: 14/50-th model tested\n",
      "Predicting on test data: 15/50-th model tested\n",
      "Predicting on test data: 16/50-th model tested\n",
      "Predicting on test data: 17/50-th model tested\n",
      "Predicting on test data: 18/50-th model tested\n",
      "Predicting on test data: 19/50-th model tested\n",
      "Predicting on test data: 20/50-th model tested\n",
      "Predicting on test data: 21/50-th model tested\n",
      "Predicting on test data: 22/50-th model tested\n",
      "Predicting on test data: 23/50-th model tested\n",
      "Predicting on test data: 24/50-th model tested\n",
      "Predicting on test data: 25/50-th model tested\n",
      "Predicting on test data: 26/50-th model tested\n",
      "Predicting on test data: 27/50-th model tested\n",
      "Predicting on test data: 28/50-th model tested\n",
      "Predicting on test data: 29/50-th model tested\n",
      "Predicting on test data: 30/50-th model tested\n",
      "Predicting on test data: 31/50-th model tested\n",
      "Predicting on test data: 32/50-th model tested\n",
      "Predicting on test data: 33/50-th model tested\n",
      "Predicting on test data: 34/50-th model tested\n",
      "Predicting on test data: 35/50-th model tested\n",
      "Predicting on test data: 36/50-th model tested\n",
      "Predicting on test data: 37/50-th model tested\n",
      "Predicting on test data: 38/50-th model tested\n",
      "Predicting on test data: 39/50-th model tested\n",
      "Predicting on test data: 40/50-th model tested\n",
      "Predicting on test data: 41/50-th model tested\n",
      "Predicting on test data: 42/50-th model tested\n",
      "Predicting on test data: 43/50-th model tested\n",
      "Predicting on test data: 44/50-th model tested\n",
      "Predicting on test data: 45/50-th model tested\n",
      "Predicting on test data: 46/50-th model tested\n",
      "Predicting on test data: 47/50-th model tested\n",
      "Predicting on test data: 48/50-th model tested\n",
      "Predicting on test data: 49/50-th model tested\n"
     ]
    }
   ],
   "source": [
    "for idx, model_path in enumerate(model_state_paths):\n",
    "    seq_deep_cpf1.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    print(f\"Predicting on test data: {idx}/{len(model_state_paths)}-th model tested\")\n",
    "    sequence_vectors, y_true, y_pred = predict(seq_deep_cpf1,device,test_dataloader)\n",
    "    predictions_by_models[idx] = (sequence_vectors, y_true, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34 bp synthetic target and target context sequence\\n(4 bp + PAM + 23 bp protospacer + 3 bp)  \\\n",
      "0                    TTGCTTTAAAACTCGCAAGGCTTTCTGCTTGACC                                            \n",
      "1                    CAGATTTAAAGACTTTCTGCTGTATTTGAGATGC                                            \n",
      "2                    GTAGTTTAAAGCCTTTTTTATTGTATCTTGTTGC                                            \n",
      "3                    CCCTTTTAAATTCTGTGCAGACCATAGTGCTGCT                                            \n",
      "4                    TTACTTTAACACTCTCAGTTGGCCCATATTCACA                                            \n",
      "...                                                 ...                                            \n",
      "1287                 CACCTTTTTTGATTATGATTACGGTGCTCCCTGT                                            \n",
      "1288                 CAGATTTTTTGCTGTTGGTGAAGGCCCTTGAAGA                                            \n",
      "1289                 TTTCTTTTTTGGCATTGCGGAGCTTATACATTCC                                            \n",
      "1290                 CTGGTTTTTTTGCTCCTTCTCGTTTTTCACAGCA                                            \n",
      "1291                 CTGTTTTTTTTTCTTCTTCCGGAGTTTGCCACTT                                            \n",
      "\n",
      "      Indel freqeuncy\\n(Background substracted, %)  CA  \n",
      "0                                        73.775671 NaN  \n",
      "1                                        68.350168 NaN  \n",
      "2                                        -5.948064 NaN  \n",
      "3                                        73.786402 NaN  \n",
      "4                                        43.073341 NaN  \n",
      "...                                            ...  ..  \n",
      "1287                                      0.117944 NaN  \n",
      "1288                                      0.120192 NaN  \n",
      "1289                                      0.330033 NaN  \n",
      "1290                                     -6.444774 NaN  \n",
      "1291                                      0.194363 NaN  \n",
      "\n",
      "[1292 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(args.test)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_no, tup in predictions_by_models.items():\n",
    "    sequence_vectors,y_true, y_pred = tup\n",
    "\n",
    "    # Fetching original sequence data\n",
    "\n",
    "    original_sequences = decoding(sequence_vectors, args.sequence_length)\n",
    "    data = {columns[0]:original_sequences, f\"{model_no}_true\": y_true.squeeze(axis=1), f\"{model_no}_pred\": y_pred.squeeze(axis=1)}  # Dimension handling\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    test_df=  pd.merge(test_df, df, on= columns[0], how= 'left')\n",
    "    \n",
    "\n",
    "\n",
    "test_df.to_excel(\"pred_result.xlsx\", engine ='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DeepCpf1_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9220f823991d29960510a6c5262d41abfc06f72b1a13c7e3e7fc60ab65baed3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
